---
title: "BadLoans"
author: "Mengshu Zhang"
date: "2023-02-07"
output: html_document
---

## R Markdown
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

**This exercise is under construction. Please report any errors at https://forms.gle/2W4tffs4YJA1jeBv9**

Goal: 
Understand and experience logistic regression to predict the probability of loan default (due to fraud or other reasons).
Build skills and confidence to search for online help.

Background:
The data for this question contains information about borrowers, loans, and the outcome (defaulted or paid). We are concerned about minimize loss, and not concerned whether the default was intentional or unintentional. I developed this assignment to walk you through the process because I couldn't find any assignment at this level that can balance fundamentals and practical aspects. The data has been derived from has been adapted from https://campus.datacamp.com/courses/credit-risk-modeling-in-r/ (but my approach is quite different).


Before starting:
1. You are not allowed to:
   1a. Search for solutions to this assignment
   2b. Subcontract your assignment to someone else
2. You are allowed to:
   2a. Search information about packages and functions you may use
   2b. Consult with your team mates.


Individual assignment only: 179 total points (Rmd and html solution)

## [1 point] Q1.
Start by entering your name and today's date in Lines 3 and 4, respectively, to indicate your compliance with the Fuqua Honor Code.
Then, run the chunk of code below by clicking on the green arrow (that points to the right) on the top right of the chunk.
*Tip:* I numbered code chunks corresponding to their numbers. Chunk 1 specifies the knitting parameters.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## [6 points] Q2.
Read and store the data from the file *LoanData.rds* into a variable called *loanData*.
Then, inspect the data using 2 or more R commands.
*Tip:* Use Google to learn about rds file format and how to read it into R. You'll likely need some libraries and packages.
*Rubric:* 3 each point for reading, 1 point for storing; 1 points each for using 2 R commands for inspecting.*
```{r}

#install.packages("tidyverse")
library(dplyr)
library(readr)
loanData <- readRDS("LoanData.rds")
str(loanData)
summary(loanData)
```


## [4 points] Q3.
I haven't provided you the data dictionary but the columns have descriptive names so you can easily interpret them. Perhaps, *homeLiving* and *creditGrade* are unclear. Figure what *homeLiving* and *creditGrade* represent by examining the the summary.
*Rubric:* 2 points for each (*homeLiving* and *creditGrade*).
```{r}
### This section doesn't require code. Just answer below (outside) the code block.
```
homeLiving means the house the person live is mortaged, owned, rented or other. 
creditGrade stands for the grade of person's credit from A to G

## [6 points] Q4.
Now, let's make sure we understand credit grade using crosstables *isLoanDefault* and *creditGrade*.
*Tip:* Follow these steps to make progress... 
1. Find, install, and load the library with CrossTable function.
2. Call CrossTable() on *creditGrade* and *isLoanDefault* columns of loanData.
*Rubric:* 4 points for finding, installing and loading the correct libraries; 2 points for calling CrossTable with the correct parameters.
```{r}
#install.packages("gmodels")
library(gmodels)
CrossTable(loanData$creditGrade, loanData$isLoanDefault)
```

## [4 points] Q5.
Based on the above answers, deduce whether or not A is the best (highest) credit rating. Explain your reasoning. 
*Tip:* The third number in each box under the loanData$isLoanDefault column is the proportion of default rate. For example, the default rate for A was 0.059 (i.e., 5.9%). You do not need to understand CrossTable beyond that to answer this question.
*Rubric:* 1 point for the correct answer, 3 points for the reasoning.
```{r}
### This section doesn't require code. Just answer below (outside) the code block.
```
*Answer:* The letter A is the best (highest) credit rating because it has the lowest default rate (0.059) and the default rate increases as the credit rating for each subsequent letter grade.


## [12 points] Q6.
Let's check for any outliers in the numeric/integer columns related to the borrowers (employmentYears, incomeAnnual, ageYears) in steps:
1. Examine the summary statistics to pick large relative gaps between the minimum and the 1st quartile as well as the maximum and the 3rd quartile. 
2. Then, display a scatter plot of all combinations of two variables, one at a time.
*Tip:* I prefer to visualize outliers using scatter plots as a combination of two variables, so I can get a better understanding of the outliers, such as a huge salary for a young person (in age or employment duration).
*Tip:* library(ggplot2) and library(gridExtra) may be useful.
*Rubric:* 3 points for each plot; 3 point for examining the summary data (on honor code).
```{r}
library(ggplot2)
library(gridExtra)
summary(loanData$employmentYears)
summary(loanData$incomeAnnual)
summary(loanData$ageYears)
ggplot(loanData, aes(x=ageYears, y=incomeAnnual,color=isLoanDefault)) + geom_point()+geom_smooth(method=lm)
ggplot(loanData, aes(x=employmentYears, y=incomeAnnual,color=isLoanDefault)) + geom_point()+geom_smooth(method=lm)
ggplot(loanData, aes(x=ageYears, y=employmentYears,color=isLoanDefault)) + geom_point()+geom_smooth(method=lm)
```

## [6 points] Q7.
Now, identify and remove any outliers and store the result in *loanDataNoOutliers*.
Then, examine loanDataNoOutliers to verify that your code worked.
*Tip:* I only removed one row. The others may be useful for our model. 
*Tip:* The structure of *loanData* and *loanDataNoOutliers* should be identical expect the number of rows be different (because you removed one or more rows).
*Rubric:* 1 points for each column; 2 point for removing, 1 point for checking.
```{r}
loanDataNoOutliers <- subset(loanData, loanData$employmentYears> (2 - 1.5*6) & loanData$employmentYears< (8 + 1.5*6))
loanDataNoOutliers <- subset(loanData, loanData$incomeAnnual> (40000 - 1.5*40000) & loanData$incomeAnnual< (80000 + 1.5*40000))
loanDataNoOutliers <- subset(loanData, loanData$ageYears> (23 - 1.5*7) & loanData$ageYears< (30 + 1.5*7))
str(loanDataNoOutliers)
```

## [3 points] Q8.
Should you report any removed row(s) for further investigation?
```{r}
### This section doesn't require code. Just answer below (outside) the code block.
```
No

## [4 points] Q9.
Why do we store the the loanData in a new variable loanDataNoOutliers? Can you imagine a scenario when you would be better off not storing the result?
*Rubric:* 2 points for each answer.
```{r}
### This section doesn't require code. Just answer below (outside) the code block.
```
We can keep records, and easy for us to track back if some steps have mistakes. 
To save more space.

## [9 points] Q10.
Now, let's handle missing data by:
1. Make a copy of *loanDataNoOutliers* and call it *loanDataNoOutliersNA*. Then, conduct the following operations on *loanDataNoOutliersNA*.
2. Compute the percentage missing (NA) values in each column. 
3. Add a new column for each variable that has missing values, as missing data can be an fraud indicator. The value of this column is 1 to indicate rows with missing values, and 0 otherwise.
4. Replace the missing values with the median value of the column if there are fewer than 10% missing values.
5. Delete the entire column if there are 10% or more missing values.
*Tip:* mean(is.na(dfName$colName))*100 gives you the percentage of missing values in colName of dfName.
*Tip:* median(dfName$colName, na.rm = TRUE) gives you the median value (ignoring all NAs).
*Tip:* The summary should be similar except the added columns and imputed data.
*Tip:* In real life, I would have asked you to use better imputation methods than just replacing by median.
*Rubric:* 0.5 points for checking each column; 4 point for handling NAs, 1 point for checking.
```{r}
loanDataNoOutliersNA <-loanDataNoOutliers
mean(is.na(loanDataNoOutliers$isLoanDefault))*100
mean(is.na(loanDataNoOutliers$loanAmount))*100
mean(is.na(loanDataNoOutliers$interestRate))*100
mean(is.na(loanDataNoOutliers$creditGrade))*100
mean(is.na(loanDataNoOutliers$employmentYears))*100
mean(is.na(loanDataNoOutliers$homeLiving))*100
mean(is.na(loanDataNoOutliers$incomeAnnual))*100
mean(is.na(loanDataNoOutliers$ageYears))*100

loanDataNoOutliersNA$naInterestRate<-ifelse(is.na(loanDataNoOutliersNA$interestRate),1,0)
loanDataNoOutliersNA$naemploymentYears<-ifelse(is.na(loanDataNoOutliersNA$employmentYears),1,0)

median_interestRate<-median(loanDataNoOutliersNA$interestRate,na.rm = TRUE)
median_employmentYears<-median(loanDataNoOutliersNA$employmentYears,na.rm = TRUE)
loanDataNoOutliersNA$interestRate<-ifelse(loanDataNoOutliersNA$naInterestRate==1,median_interestRate,loanDataNoOutliersNA$interestRate)
loanDataNoOutliersNA$employmentYears<-ifelse(loanDataNoOutliersNA$naemploymentYears==1,median_employmentYears,loanDataNoOutliersNA$employmentYears)

```


## [9 points] Q11.
We should consider some of our features (aka variables and columns) for categorization because they don't have a clear relationship with the target variable. For example, a higher interest rate may cause higher default due to financial burden while a lower interest rate may cause a higher default due to complacency (or procrastination). Which other variables should you consider for categorization?
*Rubric:* 1 points for each feature (*isLoanDefault* is not a feature)
```{r}
### This section doesn't require code. Just answer below (outside) the code block.
```
naInterestRate and naemploymentYears


## [10 points] Q12.
Before running regression, separate *loanDataNoOutliersNA* into training data (dataframe *loanTrain*) and test data (dataframe *loanTest*) using the sample() function. Start by *set.seed(2020)* so we can reproduce the randomization for multiple runs (see http://rfunction.com/archives/62 to learn more).
The dataframe *loanTest* should contains 1/3rds of *loanDataNoOutliersNA*'s rows. The dataframe *loanTrain* should contains the other 2/3rds of *loanDataNoOutliersNA*'s rows. 
Then, inspect the structure of *loanTrain* and *loanTest* to verify that your code works.
*Tip:* Follow the following steps:
1. set.seed(2020)
2. Use sample() to generate *loanTestIndices* as a sample of 1/3 of *loanDataNoOutliersNA*'s indices for testing. The remaining 2/3 will be used to train. (Note: Most people generate the 2/3 indices for training but the optimizer in me prefers to assign 1/3 as much work to my computer - this is a byproduct of working in real-time systems where every nanosecond counts).
3. Use these statements like the 2 statements below to split between test and training data.
*loanTest =  loanDataNoOutliersNA[loanTestIndices, ]* and *loanTrain = loanDataNoOutliersNA[-loanTestIndices, ]*
*Rubric:* 1 points for set.seed(), 3 points for correctly sampling, 4 points (2 each) for constructing loanTest and loanTrain, 2 point for verifying.
```{r}
set.seed(2020)
loanTestIndices <- sample(c(TRUE,FALSE), nrow(loanDataNoOutliersNA), replace = TRUE, prob = c(0.3, 0.7))
loanTest<-loanDataNoOutliersNA[loanTestIndices,]
loanTrain = loanDataNoOutliersNA[-loanTestIndices, ]
str(loanTest)
str(loanTrain)

```

## [6 points] Q13.
Run a logistic regression on *loanTrain* data and store the result in *glmBase*.
Then, print the summary of *glmBase*.
*Tip:* Your call will look something like the one below.
*glmBase = glm(target  ~ ., family = "binomial", data = trainingdata)*
Note: You will need to replace your call with the appropriate variables. (The . indicates that we will consider all features in the regression equation.)
*Tip:* I realize that some people would consider categorization at this stage. I like to learn more by running a regression now before considering categorizations. (Notice that we don't need to consider categorizing *naInterestRate* and *naEmploymentYears* because binary data is already a *factor* and ordering doesn't matter in binary data). 
*Rubric:* 5 points for the glm call, 1 point for summary
```{r}
glmBase <- glm(isLoanDefault~., data=loanTrain, family="binomial")
summary(glmBase)
```
## [9 points] Q14.
Examine the significance levels of your base model above by reviewing the *summary()*. Which variables are most significant? Which are mildly significant, and which are not very significant?
*Tip:* Focus on the last column (low *Pr(>|z|)* values) and asterisks (high significance) to determine which variables are most significant. The least significant variables have high *Pr(>|z|)* values and few asterisks. 
*Tip:* The first two columns are not useful because they are not scaled.
*Rubric:* 1 points for each feature
```{r}
### This section doesn't require code. Just answer below (outside) the code block.
```
interestRate, IncomeAnnual, creditGrade,naemploymentYears are most siginificant,
employmentYears and ageYears are midly siginificant,
loanAmount, homeliving,naInterestRate are least siginificant

## [10 points] Q15.
In real life, we would now try to optimize our model by:
  Filtering through hundreds of features (metaphorically)
  Consider categorizing or transforming variables with low significance
  etc.
However, for this exercise, we will start our predictions based on this model because we have only a few features. We may refine our model with transformations and categorizations later.
Specifically, carry out the following steps:
1. Compute the predictions for each row in the *loanTest* dataframe using the predict function and store the result in vector called *predictionsBase*. Modify the predict function below for your needs and/or Google for help.
   *predict(object = yourModel, newdata = test, type = "response")*
   where your object is your model, newdata is your test data, and type is always "response" (because that gives converts from log-odds to probability)
2. Then, append the *predictionsBase* vector to *loanTest* (as its last column).
3. Print a statistical summary of *predictionsBase*, *loanTest[, "isLoanDefault"]*, and *predictionsBase - loanTest[, "isLoanDefault"]* to check the accuracy the predictions. Relatively similar summary statistics and difference near zero and are good early signs.
*Rubric:* 6 points for correct use of predict, 1 point for appending the new column, 3 points (1 point each) for summary()
```{r}
predictionsBase <- predict(glmBase, newdata=loanTest, type="response")
loanTest <-cbind(loanTest,predictionsBase)
summary(predictionsBase)
summary(loanTest[, "isLoanDefault"])
summary(predictionsBase - loanTest[, "isLoanDefault"])
```

## [4 points] Q16.
What are your thoughts on the summary of *predictionsBase - loanTest[, "isLoanDefault"]*?
*Tip:* Check the min, median, mean, max of the value.
*Rubric:* 1 points for observing the each item in the tip.
```{r}
### This section doesn't require code. Just answer below (outside) the code block.
```
The prediction of model is accurate at some extent since the median and mean are low. However, the min of predictionsBase - loanTest[, "isLoanDefault"]* is nearly -1, and max is 0.45. 

## [4 points] Q17.
Notice that *isLoanDefault* is 0 or 1, while *predictionsBase* is a probability value (that ranges from between 0 to about 0.5). That means we need to convert the probability distribution to a 0 or 1 prediction using a cutoff value that maps each probability to either 0 or 1. A natural cutoff value is 0.5. Count the number of rows that would be classified as 0 and 1, respectively, by using the cutoff of *0.5*.
*Tip:* Add up the number of TRUE values using sum on the respective logical conditions.
*Rubric:* 2 points each.
```{r}
sum(ifelse(predictionsBase>0.5,1,0))
sum(ifelse(predictionsBase<0.5,1,0))
```

## [6 points] Q18.
Consider the cutoff of 0.5 based on the output from the last chunk. Would you adjust the cutoff value? Why? How?
*Tip:* I learned this on my own and this was an important lesson for choosing the cutoff values.
*Rubric:* 2 points for each question above
```{r}
### This section doesn't require code. Just answer below (outside) the code block.

```
I would adjust the cutoff value whose sensitivity and specificity are the closest to the value of the area under the ROC curve and the absolute value of the difference between the sensitivity and specificity values is minimum.
(from google)

## [6 points] Q19. 
Now, set a value for a variable called *cutoff* that improves the cutoff value based on what you know about your model and the data. 
Then, use this *cutoff* value to compute a new column vector called *isPrediction* based on *predictionsBase*.
Then, add this vector as the first column of *loanTest* (so it can be side by side with *isLoanDefault*).
Finally, print a summary of *loanTest* to verify that your code works.
*Tip:* I based my *cutoff* on the fact that 0.1121 of test cases are bad loans. Specifically, I sorted the *predictionsBase* vector in non-decreasing order (using *sort()* function with *decreasing = TRUE*), and then I set the value of *cutoff* equal to value of the element number **as.integer(0.1121 * length(sortedPredictionBase)) of the sorted list.**
*Rubric:* 2 points each for choice of *cutoff* and generating is *isPrediction*; 1 point each for adding *isPrediction* as the first column of *loanTest* and verifying the result.
```{r}
sortedPredictionBase <-sort(predictionsBase,decreasing = TRUE)
sortedPredictionBase
cutoff <- as.integer(0.1121 * length(sortedPredictionBase))
cutoff <- sortedPredictionBase[cutoff]
isPrediction <- ifelse(predictionsBase > cutoff, 1, 0)
loanTest <- cbind(isPrediction, loanTest)
summary(loanTest)
```

## [8 points] Q20. 
Now, compute the number of True Negatives, False Negatives, False Positives, True Positives, respectively. Store the results in tneg, fneg, fpos, and tpos, respectively.
Then, print all four values.
*Tip:* **tneg = sum( (0 == loanTest$isPrediction) & (0 == loanTest$isLoanDefault))**
*Rubric:* 2 point of each value.
```{r}
tneg = sum( (0 == loanTest$isPrediction) & (0 == loanTest$isLoanDefault))
fneg = sum( (0 == loanTest$isPrediction) & (1 == loanTest$isLoanDefault))
fpos = sum( (1 == loanTest$isPrediction) & (0 == loanTest$isLoanDefault))
tpos = sum( (1 == loanTest$isPrediction) & (1 == loanTest$isLoanDefault))
```

## [8 points] Q21. 
Now, let's use the *confusionMatrix()* function to gauge the model's confusion. The *confusionMatrix()* function is similar to our true/false negatives/positives calculations above but it also generates more data.
*Tip:* You will need to install/library caret and e1071 to call *confusionMatrix()* as shown below:
*confusionMatrix(data = as.factor(predicted), reference =as.factor(actual))*
Notice that we have to convert integers to factors. The predicted parameter is *loanTest$isPrediction* and the actual parameter is *loanTest$isLoanDefault*.
*Rubric:* 4 points for installing libraries. 4 points for using *confusionMatrix()*.
```{r}
library(caret)
#install.packages("e1071")
library(e1071)
confusionMatrix(data = as.factor(loanTest$isPrediction), reference =as.factor(loanTest$isLoanDefault))

```

## [6 points] Q22.
Now, let's return to our choice of cutoff to understand how this choice impacts the Accuracy, Sensitivity, and Specificity.
Run the code below to print the confusion matrix for *cutoff* you used earlier, and verify that this gives you the same results as the previous chunk (while bypassing a lot of of other code).
Then, learn about confusion matrix by Googling "accuracy sensitivity specificity confusion matrix" and/or reading https://towardsdatascience.com/taking-the-confusion-out-of-confusion-matrices-c1ce054b3d3e.
*Rubric:* 1 point for running the code; 3 points for learning more about confusion matrix (based on honor code)
```{r}
### Do not edit this code, just run it!
confusionMatrix(data = as.factor(as.numeric(cutoff < loanTest$predictionsBase)), 
                reference = as.factor(loanTest$isLoanDefault))
```


## [6 points] Q23.
Now, increase the cutoff by 10 percent and report if the following parameters increased or decreased compared to your original cutoff: *Accuracy*, *Sensitivity*, and *Specificity*?
*Tip:* Ignore any warnings.
*Rubric:* 2 points for each Accuracy, Sensitivity, and Specificity
```{r}
confusionMatrix(data = as.factor(as.numeric(cutoff*1.1 < loanTest$predictionsBase)), 
                reference = as.factor(loanTest$isLoanDefault))

### Complete the following phrases:
## The Accuracy increase  
## The Sensitivity increase
## The Specificity decrease
```


## [6 points] Q24.
Now, decrease the cutoff by 10 percent and report if the following parameters increased or decreased: *Accuracy*, *Sensitivity*, and *Specificity*?
*Rubric:* 2 points for each Accuracy, Sensitivity, and Specificity
```{r}
confusionMatrix(data = as.factor(as.numeric(cutoff*0.9 < loanTest$predictionsBase)), 
                reference = as.factor(loanTest$isLoanDefault))

### Complete the following phrases:
## The Accuracy decrease
## The Sensitivity decrease
## The Specificity increase
```

## [5 points] Q25.
Find the maximum value you can set to replace 0.1 below without generating an warning.
*Tip:* The summary of predictionsBase will give you a clue.
```{r}
### Do not edit any other than 0.1 in this code, just run it!
summary(loanTest$predictionsBase)
### Changed 0.4958791 to 0.1 for assignment
confusionMatrix(data = as.factor(as.numeric(0.1 < loanTest$predictionsBase)), 
                reference = as.factor(loanTest$isLoanDefault))
```

## [3 points] Q26.
What is the danger in maximizing the accuracy?
*Tip:* Review the confusion matrices above.
```{r}
### This section doesn't require code. Just answer below (outside) the code block.
```
It may make the dataset imbalanced

## [5 points] Q27.
Examine the output from Chunk 13 and run a new regression with (only) the top 5 predictors of the target variable, and store the result in *glmTop5*. 
Then, print the summary of *glmTop5*.
*Rubric:* 1 point for each of the top 5 predictors.
```{r}
glmTop5 <- glm(isLoanDefault~ interestRate+incomeAnnual+naemploymentYears+creditGrade+employmentYears, data=loanTrain, family="binomial")
summary(glmTop5)
```

## [3 points] Q28.
Examine the output from the previous chunk and run a new regression with (only) the top 3 predictors of the target variable, and store the result in *glmTop3*. 
Then, print the summary of *glmTop3*.
*Rubric:* 1 point for each of the top 3 predictors.
```{r}
glmTop3 <- glm(isLoanDefault~ creditGrade+incomeAnnual+naemploymentYears, data=loanTrain, family="binomial")
summary(glmTop3)
```

## [5 points] Q29.
Based on the AIC scores which one of the following would you choose for modeling and why: glmBase, glmTop5, glmTop3?
```{r}
### This section doesn't require code but feel free to reprint any critical values.

```
*Answer:*
I'll choose to run glmTop3 since it has higher AIC scores, and variables are statistically significant.

## [5 points] Q30. 
*Knit to html after eliminating all the errors. Submit both the Rmd and html files.* 
*Tip: Do not worry about minor formatting issues.*
*Tip: This will take some time as you are processing medium size data sets.*
```{r}
### This section doesn't require code. Just knit and submit the Rmd and html files.### 
```


